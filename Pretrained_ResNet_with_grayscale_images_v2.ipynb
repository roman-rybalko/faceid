{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How can I use a pre-trained neural network with grayscale images?\n",
        "This work is aimed to validate this answer at StackOverflow: https://stackoverflow.com/questions/51995977/how-can-i-use-a-pre-trained-neural-network-with-grayscale-images#answer-54777347\n",
        "\n",
        "The idea is to fix the first convolution layer by summing up the weights over the color channels."
      ],
      "metadata": {
        "id": "HFyk5J-NrEhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -Rf data* cache debug*\n",
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj2NGCEhBT5V",
        "outputId": "2f098662-2ffe-4866-d2f0-28226c78a57e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4\n",
            "drwxr-xr-x 1 root root 4096 Sep 14 13:44 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.kaggle.com/datasets/ifigotin/imagenetmini-1000\n",
        "!wget -O data.zip 'https://storage.googleapis.com/kaggle-data-sets/547506/998277/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20220916%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20220916T190126Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=250534aa0e9a8fb7744fd44ac4bcc01081c5feb875ae4765228e82049a7bd604a6d5028d9a30dd0a4e1bf1b0b652eb04e7c6b1cec61926fbe6894fae4dfb088043d807c650f46dd07d71fbc3c91b1d7520b58d9b5593260864fb78219208aa9da6b83cf57a89599d4624722fd0e26c58eaea20e71f80f6f1a29d2b249f78f1a66620c6baff0189b442532abb9e5b6c4db8bb78421b441e2c800f7765057e545eadc63a04d407afb6c6dfa54efb4080350d36e268c479d3e577d57d8b599a9f41e498293e2d80f769456e1e81cc73a7045f55392aef9b5cb4faffb8b7187b0a308ad65bd663380c067cc89a69c0e8f9d15b9abedc9d0c9eea78f275d47da822fc'\n",
        "!unzip -q -d data data.zip"
      ],
      "metadata": {
        "id": "xvZXslr6rLA2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c5ece75-1581-47df-c360-16d8bcf3f6b9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-16 20:57:32--  https://storage.googleapis.com/kaggle-data-sets/547506/998277/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20220916%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20220916T190126Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=250534aa0e9a8fb7744fd44ac4bcc01081c5feb875ae4765228e82049a7bd604a6d5028d9a30dd0a4e1bf1b0b652eb04e7c6b1cec61926fbe6894fae4dfb088043d807c650f46dd07d71fbc3c91b1d7520b58d9b5593260864fb78219208aa9da6b83cf57a89599d4624722fd0e26c58eaea20e71f80f6f1a29d2b249f78f1a66620c6baff0189b442532abb9e5b6c4db8bb78421b441e2c800f7765057e545eadc63a04d407afb6c6dfa54efb4080350d36e268c479d3e577d57d8b599a9f41e498293e2d80f769456e1e81cc73a7045f55392aef9b5cb4faffb8b7187b0a308ad65bd663380c067cc89a69c0e8f9d15b9abedc9d0c9eea78f275d47da822fc\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.197.128, 74.125.135.128, 74.125.142.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.197.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4211443423 (3.9G) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   3.92G   149MB/s    in 29s     \n",
            "\n",
            "2022-09-16 20:58:01 (141 MB/s) - ‘data.zip’ saved [4211443423/4211443423]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from tqdm import tqdm # progress bar\n",
        "import matplotlib.pyplot as plt # drawing\n",
        "\n",
        "import os\n",
        "fcnt = 0\n",
        "for dirname, _, filenames in os.walk('data'):\n",
        "  for filename in filenames:\n",
        "    fcnt += 1\n",
        "    if fcnt < 10:\n",
        "      print(os.path.join(dirname, filename))\n",
        "print(fcnt)"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-09-16T16:09:32.161087Z",
          "iopub.execute_input": "2022-09-16T16:09:32.161584Z",
          "iopub.status.idle": "2022-09-16T16:09:53.666660Z",
          "shell.execute_reply.started": "2022-09-16T16:09:32.161490Z",
          "shell.execute_reply": "2022-09-16T16:09:53.665449Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8Vm1QcnrEh7",
        "outputId": "02fbcad1-f723-401c-82f9-da80576492a2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/imagenet-mini/train/n02165105/n02165105_130.JPEG\n",
            "data/imagenet-mini/train/n02165105/n02165105_1487.JPEG\n",
            "data/imagenet-mini/train/n02165105/n02165105_9230.JPEG\n",
            "data/imagenet-mini/train/n02165105/n02165105_2027.JPEG\n",
            "data/imagenet-mini/train/n02165105/n02165105_413.JPEG\n",
            "data/imagenet-mini/train/n02165105/n02165105_1003.JPEG\n",
            "data/imagenet-mini/train/n02165105/n02165105_6979.JPEG\n",
            "data/imagenet-mini/train/n02165105/n02165105_11806.JPEG\n",
            "data/imagenet-mini/train/n02165105/n02165105_8750.JPEG\n",
            "38668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'data/imagenet-mini/train'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T16:09:53.668904Z",
          "iopub.execute_input": "2022-09-16T16:09:53.669570Z",
          "iopub.status.idle": "2022-09-16T16:09:53.673951Z",
          "shell.execute_reply.started": "2022-09-16T16:09:53.669534Z",
          "shell.execute_reply": "2022-09-16T16:09:53.673032Z"
        },
        "trusted": true,
        "id": "l4XrdSnirEh_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T16:09:53.675193Z",
          "iopub.execute_input": "2022-09-16T16:09:53.676339Z",
          "iopub.status.idle": "2022-09-16T16:09:55.661776Z",
          "shell.execute_reply.started": "2022-09-16T16:09:53.676272Z",
          "shell.execute_reply": "2022-09-16T16:09:55.660600Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkB4hETErEiA",
        "outputId": "085dfe92-634e-44ed-99f0-ef309c2db067"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "\n",
        "class ImageNetDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, data_dir, transform=None):\n",
        "    self.transform = transform\n",
        "    self.data = []\n",
        "    for cl in tqdm(os.listdir(data_dir), desc='data'):\n",
        "      for f in os.listdir(f'{data_dir}/{cl}'):\n",
        "        self.data += [(f'{data_dir}/{cl}/{f}', cl)]\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    assert index >= 0\n",
        "    assert index < len(self.data)\n",
        "    f, cl = self.data[index]\n",
        "    img = PIL.Image.open(f).convert('RGB')\n",
        "    if self.transform:\n",
        "      img = self.transform(img)\n",
        "    return img, cl, f\n",
        "  \n",
        "  def classes(self):\n",
        "    return list(set(cl for f, cl in self.data))\n",
        "  \n",
        "  def get_class(self, index):\n",
        "    assert index >= 0\n",
        "    assert index < len(self.data)\n",
        "    f, cl = self.data[index]\n",
        "    return cl\n",
        "\n",
        "dataset = ImageNetDataset(data_dir)\n",
        "len(dataset), len(dataset.classes())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T16:09:59.483278Z",
          "iopub.execute_input": "2022-09-16T16:09:59.483893Z",
          "iopub.status.idle": "2022-09-16T16:10:00.070141Z",
          "shell.execute_reply.started": "2022-09-16T16:09:59.483856Z",
          "shell.execute_reply": "2022-09-16T16:10:00.069357Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIDCbGlrrEiB",
        "outputId": "7b3eb864-b19f-4dac-b65d-8c5eba469f9e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "data: 100%|██████████| 1000/1000 [00:00<00:00, 19429.14it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34745, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, loader, out_cnt=1000):\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  predictions = []\n",
        "  weights = []\n",
        "  for x, _, _ in tqdm(loader, desc='eval'):\n",
        "    ws = model(x.to(device))\n",
        "    weights += [ws.cpu().detach().reshape(-1, out_cnt)]\n",
        "    predictions += [torch.argmax(ws, dim=1).cpu().detach().reshape(-1, 1)]\n",
        "  return np.vstack(predictions), np.vstack(weights)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T16:10:03.986642Z",
          "iopub.execute_input": "2022-09-16T16:10:03.987034Z",
          "iopub.status.idle": "2022-09-16T16:10:03.994759Z",
          "shell.execute_reply.started": "2022-09-16T16:10:03.987004Z",
          "shell.execute_reply": "2022-09-16T16:10:03.993546Z"
        },
        "trusted": true,
        "id": "cmOzgl74rEiD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics\n",
        "from collections import Counter\n",
        "\n",
        "def metrics(classes, dataset):\n",
        "  assert len(classes) == len(dataset)\n",
        "  classes = classes.reshape(-1)\n",
        "  gt_classes = np.copy(classes)\n",
        "  cl_id = {}\n",
        "  orig_classes = []\n",
        "  for i in range(len(dataset)):\n",
        "    # find sample ids for each class\n",
        "    cl = dataset.get_class(i)\n",
        "    orig_classes += [cl]\n",
        "    if cl in cl_id:\n",
        "      cl_id[cl] += [i]\n",
        "    else:\n",
        "      cl_id[cl] = [i]\n",
        "  for cl in cl_id.keys():\n",
        "    # guess the class - pick the most common class_id\n",
        "    cmn_cl = Counter(classes[cl_id[cl]]).most_common(1)[0][0]\n",
        "    gt_classes[cl_id[cl]] = cmn_cl\n",
        "  return sklearn.metrics.precision_score(gt_classes, classes, average='micro')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T16:28:12.578661Z",
          "iopub.execute_input": "2022-09-16T16:28:12.579073Z",
          "iopub.status.idle": "2022-09-16T16:28:12.590767Z",
          "shell.execute_reply.started": "2022-09-16T16:28:12.579038Z",
          "shell.execute_reply": "2022-09-16T16:28:12.589588Z"
        },
        "trusted": true,
        "id": "PJijcqQUrEiE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "\n",
        "def validate(model, dataset):\n",
        "  data_loader = torch.utils.data.DataLoader(dataset, batch_size=16, num_workers=psutil.cpu_count())\n",
        "  cl, w = predict(model, data_loader)\n",
        "  return metrics(cl, dataset)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T16:10:11.254662Z",
          "iopub.execute_input": "2022-09-16T16:10:11.255281Z",
          "iopub.status.idle": "2022-09-16T16:10:11.261723Z",
          "shell.execute_reply.started": "2022-09-16T16:10:11.255224Z",
          "shell.execute_reply": "2022-09-16T16:10:11.260551Z"
        },
        "trusted": true,
        "id": "Gc7L0bM3rEiG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rn_transform = torchvision.transforms.Compose([\n",
        "  torchvision.transforms.Resize((224, 224)),\n",
        "  torchvision.transforms.ToTensor(),\n",
        "  torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def resnet_transform(img):\n",
        "  img = rn_transform(img)\n",
        "  return img"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T16:10:27.652525Z",
          "iopub.execute_input": "2022-09-16T16:10:27.652936Z",
          "iopub.status.idle": "2022-09-16T16:10:27.661415Z",
          "shell.execute_reply.started": "2022-09-16T16:10:27.652900Z",
          "shell.execute_reply": "2022-09-16T16:10:27.659962Z"
        },
        "trusted": true,
        "id": "FzYT3REtrEiK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate(\n",
        "  torchvision.models.resnet18(weights='DEFAULT'),\n",
        "  ImageNetDataset(data_dir, resnet_transform)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTrEutp4-KZt",
        "outputId": "4213ed4f-175c-4407-bd26-01d07f3ba524"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "data: 100%|██████████| 1000/1000 [00:00<00:00, 21863.89it/s]\n",
            "eval: 100%|██████████| 2172/2172 [03:59<00:00,  9.06it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7440207224061016"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validate(\n",
        "  torchvision.models.resnet50(weights='DEFAULT'),\n",
        "  ImageNetDataset(data_dir, resnet_transform)\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T16:28:21.323246Z",
          "iopub.execute_input": "2022-09-16T16:28:21.324543Z",
          "iopub.status.idle": "2022-09-16T16:31:16.585707Z",
          "shell.execute_reply.started": "2022-09-16T16:28:21.324496Z",
          "shell.execute_reply": "2022-09-16T16:31:16.584429Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UmROvDMrEiM",
        "outputId": "f13b5542-d09a-4e71-8757-a17493879c67"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "data: 100%|██████████| 1000/1000 [00:00<00:00, 22390.76it/s]\n",
            "eval: 100%|██████████| 2172/2172 [04:15<00:00,  8.52it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9063174557490287"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gr_transform = torchvision.transforms.Compose([\n",
        "  torchvision.transforms.Resize((224, 224)),\n",
        "  torchvision.transforms.functional.to_grayscale,\n",
        "  torchvision.transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def grayscale_transform(img):\n",
        "  img = gr_transform(img)\n",
        "  return img\n",
        "\n",
        "def grayscale_fix_model(model):\n",
        "  w = model.conv1.weight.data.sum(axis=1).reshape(64, 1, 7, 7)\n",
        "  model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "  model.conv1.weight.data = w\n",
        "  return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T17:30:35.959802Z",
          "iopub.execute_input": "2022-09-16T17:30:35.960213Z",
          "iopub.status.idle": "2022-09-16T17:30:35.968348Z",
          "shell.execute_reply.started": "2022-09-16T17:30:35.960180Z",
          "shell.execute_reply": "2022-09-16T17:30:35.967079Z"
        },
        "trusted": true,
        "id": "LQVxDTTBrEiN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate(\n",
        "  grayscale_fix_model(torchvision.models.resnet18(weights='DEFAULT')),\n",
        "  ImageNetDataset(data_dir, grayscale_transform)\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T17:32:06.566786Z",
          "iopub.execute_input": "2022-09-16T17:32:06.567223Z",
          "iopub.status.idle": "2022-09-16T17:34:46.772452Z",
          "shell.execute_reply.started": "2022-09-16T17:32:06.567185Z",
          "shell.execute_reply": "2022-09-16T17:34:46.771412Z"
        },
        "trusted": true,
        "id": "wuTIavqNrEiP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "606dc03e-1538-47a5-f399-fe5452add474"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "data: 100%|██████████| 1000/1000 [00:00<00:00, 24141.27it/s]\n",
            "eval: 100%|██████████| 2172/2172 [03:29<00:00, 10.35it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33898402647863"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validate(\n",
        "  grayscale_fix_model(torchvision.models.resnet50(weights='DEFAULT')),\n",
        "  ImageNetDataset(data_dir, grayscale_transform)\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T16:54:27.826670Z",
          "iopub.execute_input": "2022-09-16T16:54:27.827040Z",
          "iopub.status.idle": "2022-09-16T17:00:39.097454Z",
          "shell.execute_reply.started": "2022-09-16T16:54:27.827003Z",
          "shell.execute_reply": "2022-09-16T17:00:39.095350Z"
        },
        "trusted": true,
        "id": "m0t4sMuRrEiQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aa3f135-44bb-42bc-9c90-a1730e0ab8a5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "data: 100%|██████████| 1000/1000 [00:00<00:00, 21000.40it/s]\n",
            "eval: 100%|██████████| 2172/2172 [03:50<00:00,  9.43it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7534033673909916"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gr_transform = torchvision.transforms.Compose([\n",
        "  torchvision.transforms.Resize((224, 224)),\n",
        "  torchvision.transforms.ToTensor(),\n",
        "  torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "  torchvision.transforms.ToPILImage(),\n",
        "  torchvision.transforms.functional.to_grayscale,\n",
        "  torchvision.transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def grayscale_transform(img):\n",
        "  img = gr_transform(img)\n",
        "  return img"
      ],
      "metadata": {
        "id": "_ygbmab0rEiQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate(\n",
        "  grayscale_fix_model(torchvision.models.resnet18(weights='DEFAULT')),\n",
        "  ImageNetDataset(data_dir, grayscale_transform)\n",
        ")"
      ],
      "metadata": {
        "id": "oOITauVHrEiR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72663e79-dd91-4e48-cba9-e53c5b38962e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "data: 100%|██████████| 1000/1000 [00:00<00:00, 24522.50it/s]\n",
            "eval: 100%|██████████| 2172/2172 [04:20<00:00,  8.34it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.26182184486976545"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validate(\n",
        "  grayscale_fix_model(torchvision.models.resnet50(weights='DEFAULT')),\n",
        "  ImageNetDataset(data_dir, grayscale_transform)\n",
        ")"
      ],
      "metadata": {
        "id": "5WsLbD9VrEiT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "652fc1cd-f1e9-44cb-8729-327a43d04043"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "data: 100%|██████████| 1000/1000 [00:00<00:00, 26448.64it/s]\n",
            "eval: 100%|██████████| 2172/2172 [04:32<00:00,  7.98it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19202762987480212"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gr_transform = torchvision.transforms.Compose([\n",
        "  torchvision.transforms.Resize((224, 224)),\n",
        "  torchvision.transforms.functional.autocontrast,\n",
        "  torchvision.transforms.functional.to_grayscale,\n",
        "  torchvision.transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def grayscale_transform(img):\n",
        "  img = gr_transform(img)\n",
        "  return img"
      ],
      "metadata": {
        "id": "Z3GhoisFrEiT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate(\n",
        "  grayscale_fix_model(torchvision.models.resnet18(weights='DEFAULT')),\n",
        "  ImageNetDataset(data_dir, grayscale_transform)\n",
        ")"
      ],
      "metadata": {
        "id": "aMoaZyPZrEiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "246a831f-34a7-4f1c-cc24-097db0765bd6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "data: 100%|██████████| 1000/1000 [00:00<00:00, 23326.44it/s]\n",
            "eval: 100%|██████████| 2172/2172 [03:29<00:00, 10.36it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3505540365520219"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validate(\n",
        "  grayscale_fix_model(torchvision.models.resnet50(weights='DEFAULT')),\n",
        "  ImageNetDataset(data_dir, grayscale_transform)\n",
        ")"
      ],
      "metadata": {
        "id": "8NPuTvEBrEiV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b539c38-2f86-4fb5-b524-907701cb368a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "data: 100%|██████████| 1000/1000 [00:00<00:00, 22442.99it/s]\n",
            "eval: 100%|██████████| 2172/2172 [03:45<00:00,  9.64it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7551014534465391"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}