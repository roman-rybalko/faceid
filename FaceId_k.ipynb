{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfcnt = 0\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        fcnt += 1\n        if fcnt < 20:\n            print(os.path.join(dirname, filename))\nprint(fcnt)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-09-22T12:06:37.571555Z","iopub.execute_input":"2022-09-22T12:06:37.571949Z","iopub.status.idle":"2022-09-22T12:06:37.597442Z","shell.execute_reply.started":"2022-09-22T12:06:37.571882Z","shell.execute_reply":"2022-09-22T12:06:37.596449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!df /kaggle/","metadata":{"execution":{"iopub.status.busy":"2022-09-22T12:06:37.600239Z","iopub.execute_input":"2022-09-22T12:06:37.600509Z","iopub.status.idle":"2022-09-22T12:06:38.547347Z","shell.execute_reply.started":"2022-09-22T12:06:37.600483Z","shell.execute_reply":"2022-09-22T12:06:38.546160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -pv /kaggle/temp\n!rm -Rf /kaggle/temp/*\n!cp -as /kaggle/input/youtube-faces-with-facial-keypoints /kaggle/temp/\n!mv /kaggle/temp/youtube-faces-with-facial-keypoints/*/*/*.npz /kaggle/temp/youtube-faces-with-facial-keypoints/\n!ls /kaggle/temp/youtube-faces-with-facial-keypoints/ | wc","metadata":{"execution":{"iopub.status.busy":"2022-09-22T12:06:38.549486Z","iopub.execute_input":"2022-09-22T12:06:38.549935Z","iopub.status.idle":"2022-09-22T12:06:44.735811Z","shell.execute_reply.started":"2022-09-22T12:06:38.549890Z","shell.execute_reply":"2022-09-22T12:06:44.734585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/temp/youtube-faces-with-facial-keypoints'","metadata":{"execution":{"iopub.status.busy":"2022-09-22T12:06:44.739439Z","iopub.execute_input":"2022-09-22T12:06:44.739763Z","iopub.status.idle":"2022-09-22T12:06:44.748598Z","shell.execute_reply.started":"2022-09-22T12:06:44.739732Z","shell.execute_reply":"2022-09-22T12:06:44.746014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Updating to the recent pretrained data\n!rm -Rf ~/.cache/torch/hub/checkpoints/\n!mkdir -pv ~/.cache/torch/hub/checkpoints/\n!cp -avs /kaggle/input/torchvision-resnet-pretrained/resnet*.pth ~/.cache/torch/hub/checkpoints/\n!mv -vf ~/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth ~/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n!mv -vf ~/.cache/torch/hub/checkpoints/resnet101-cd907fc2.pth ~/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n!mv -vf ~/.cache/torch/hub/checkpoints/resnet152-f82ba261.pth ~/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n!ls -l /root/.cache/torch/hub/checkpoints/","metadata":{"execution":{"iopub.status.busy":"2022-09-22T12:06:44.750559Z","iopub.execute_input":"2022-09-22T12:06:44.750931Z","iopub.status.idle":"2022-09-22T12:06:51.372236Z","shell.execute_reply.started":"2022-09-22T12:06:44.750896Z","shell.execute_reply":"2022-09-22T12:06:51.371120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm","metadata":{"id":"xcDdqMb8jWEY","execution":{"iopub.status.busy":"2022-09-22T12:06:51.373793Z","iopub.execute_input":"2022-09-22T12:06:51.374112Z","iopub.status.idle":"2022-09-22T12:06:51.382574Z","shell.execute_reply.started":"2022-09-22T12:06:51.374080Z","shell.execute_reply":"2022-09-22T12:06:51.381563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(f'{data_dir}/youtube_faces_with_keypoints_full.csv')\ndf = df[:20]\ndf","metadata":{"id":"9Wpb5ohLj5VI","outputId":"ca513529-baef-44a8-9825-ab8ac718af30","execution":{"iopub.status.busy":"2022-09-22T12:06:51.384659Z","iopub.execute_input":"2022-09-22T12:06:51.385067Z","iopub.status.idle":"2022-09-22T12:06:51.421341Z","shell.execute_reply.started":"2022-09-22T12:06:51.385033Z","shell.execute_reply":"2022-09-22T12:06:51.420473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\n#from torchinfo import summary","metadata":{"id":"sJguPEzWihnZ","execution":{"iopub.status.busy":"2022-09-22T12:06:51.422475Z","iopub.execute_input":"2022-09-22T12:06:51.422909Z","iopub.status.idle":"2022-09-22T12:06:52.042656Z","shell.execute_reply.started":"2022-09-22T12:06:51.422875Z","shell.execute_reply":"2022-09-22T12:06:52.041663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice, torch.cuda.get_device_properties(device) if torch.cuda.is_available() else 'CPU'","metadata":{"id":"dLXqSfVskgi9","outputId":"ade42169-dfd1-4fdc-d231-e5b5a51c6561","execution":{"iopub.status.busy":"2022-09-22T12:06:52.044197Z","iopub.execute_input":"2022-09-22T12:06:52.044942Z","iopub.status.idle":"2022-09-22T12:06:52.088824Z","shell.execute_reply.started":"2022-09-22T12:06:52.044899Z","shell.execute_reply":"2022-09-22T12:06:52.087528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import PIL\nimport cv2\n\nclass NormalizeTransform:\n    def __init__(self, ratio=0.333):\n        self.ratio = ratio\n\n        self.jawPoints                    = [ 0,17]\n        self.rigthEyebrowPoints = [17,22]\n        self.leftEyebrowPoints    = [22,27]\n        self.noseRidgePoints        = [27,31]\n        self.noseBasePoints         = [31,36]\n        self.rightEyePoints         = [36,42]\n        self.leftEyePoints            = [42,48]\n        self.outerMouthPoints     = [48,60]\n        self.innerMouthPoints     = [60,68]\n\n        self.norm_transform = torchvision.transforms.Compose([\n            torchvision.transforms.Resize((224, 224)),\n            torchvision.transforms.functional.autocontrast,\n            torchvision.transforms.functional.to_grayscale,\n            torchvision.transforms.ToTensor(),\n        ])\n\n    def __call__(self, data, landmarks):\n        data = self.face_transform(data, landmarks)\n        img = PIL.Image.fromarray(data)\n        data = self.norm_transform(img)\n        return data\n\n    def face_transform(self, data, landmarks):\n        # see FaceId-Normalization.ipynb\n        pt1 = self.avg(landmarks[self.leftEyePoints[0]:self.leftEyePoints[1]])\n        pt2 = self.avg(landmarks[self.outerMouthPoints[0]:self.outerMouthPoints[1]])\n        pt3 = self.avg(landmarks[self.rightEyePoints[0]:self.rightEyePoints[1]])\n        src_pts = np.float32([pt1, pt2, pt3])\n        dst_pts = np.float32([\n            [data.shape[0]*self.ratio, data.shape[1]*self.ratio],\n            [data.shape[0]/2, data.shape[1]*(1-self.ratio)],\n            [data.shape[0]*(1-self.ratio), data.shape[1]*self.ratio]\n        ])\n        M = cv2.getAffineTransform(src_pts, dst_pts)\n        data = cv2.warpAffine(data, M, data.shape[:2])\n        return data\n    \n    def avg(self, pts):\n        x = sum(x for x,y in pts) / len(pts)\n        y = sum(y for x,y in pts) / len(pts)\n        return x, y","metadata":{"id":"NfaI6TWnkpWw","execution":{"iopub.status.busy":"2022-09-22T12:06:52.090509Z","iopub.execute_input":"2022-09-22T12:06:52.091060Z","iopub.status.idle":"2022-09-22T12:06:52.125494Z","shell.execute_reply.started":"2022-09-22T12:06:52.091023Z","shell.execute_reply":"2022-09-22T12:06:52.124636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import bisect\nimport random\n\nclass YouTubeFacesDataset(torch.utils.data.Dataset):\n    def __init__(self, df, folder='.', transform=NormalizeTransform(), cache_lim=200, preload=False):\n        self.transform = transform\n        self.cache = {}\n        self.cache_lim = 0 if preload else cache_lim\n        self.data = {}\n        for p in tqdm(df['personName'].unique(), desc='Loading data'):\n            self.data[p] = []\n            for fn, cnt in df[df['personName'] == p][['videoID', 'videoDuration']].values:\n                fp = f'{folder}/{fn}.npz'\n                cnt = int(cnt)\n                self.data[p] += [(fp, i) for i in range(cnt)]\n                if preload:\n                    self.cache_lim += 1\n                    self._cache_get(fp)\n        self.persons = list(self.data.keys())\n        self.neg_data = {}\n        for p in self.persons:\n            self.neg_data[p] = []\n            for p_neg in self.persons:\n                if p_neg == p:\n                    continue\n                self.neg_data[p] += self.data[p_neg]\n        self.pers_item_counter = []\n        for p in self.persons:\n            # random positive set\n            positive_set_len = 1\n            self.pers_item_counter += [positive_set_len * len(self.neg_data[p])]\n            if len(self.pers_item_counter) > 1:\n                self.pers_item_counter[-1] += self.pers_item_counter[-2]\n    \n    def __len__(self):\n        # random positive set\n        return sum(len(x) for x in self.neg_data.values())\n    \n    def __getitem__(self, index):\n        p_i = bisect.bisect_left(self.pers_item_counter, index + 1)\n        assert p_i >= 0\n        assert p_i < len(self.persons)\n        p = self.persons[p_i]\n        anchor_i = (self.pers_item_counter[p_i] - index) % len(self.data[p])\n        assert anchor_i >= 0\n        assert anchor_i < len(self.data[p])\n        positive_i = random.randint(0, len(self.data[p]) - 1)\n        while positive_i == anchor_i:\n            positive_i = random.randint(0, len(self.data[p]) - 1)\n        assert positive_i >= 0\n        assert positive_i < len(self.data[p])\n        # the order does not matter\n        negative_i = self.pers_item_counter[p_i] - index - 1\n        assert negative_i >= 0, (p_i, index, self.persons[p_i], self.pers_item_counter[p_i])\n        assert negative_i < len(self.neg_data[p])\n        return self._load(*self.data[p][anchor_i]), self._load(*self.data[p][positive_i]), self._load(*self.neg_data[p][negative_i])\n    \n    def _load(self, fp, i):\n        imgs, lms = self._cache_get(fp)\n        assert i < imgs.shape[-1], (fp, i, imgs.shape[-1])\n        data = imgs[:,:,:,i]\n        assert i < lms.shape[-1], (fp, i, lms.shape[-1])\n        lms = lms[:,:,i]\n        if self.transform:\n            data = self.transform(data, lms)\n        return data\n    \n    def _cache_get(self, fp):\n        if fp in self.cache:\n            return self.cache[fp]\n        if len(self.cache) > self.cache_lim:\n            idx = random.randint(0, len(self.cache) - 1)\n            key = list(self.cache.keys())[idx]\n            del self.cache[key]\n        d = np.load(fp)\n        # trigger lazy loading\n        self.cache[fp] = (d['colorImages'], d['landmarks2D'])\n        return self.cache[fp]\n\ndataset = YouTubeFacesDataset(df, data_dir, preload=True)\nlen(dataset), len(dataset[42]), len(dataset[0]), len(dataset[len(dataset)-1])","metadata":{"id":"K6M-NqdtlvAN","outputId":"7dba579b-5797-41d8-fdfb-4bbe6b901641","execution":{"iopub.status.busy":"2022-09-22T12:06:52.126785Z","iopub.execute_input":"2022-09-22T12:06:52.127135Z","iopub.status.idle":"2022-09-22T12:06:54.358315Z","shell.execute_reply.started":"2022-09-22T12:06:52.127100Z","shell.execute_reply":"2022-09-22T12:06:54.357414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to_pil_transform = torchvision.transforms.ToPILImage()\nto_pil_transform(dataset[42][1])","metadata":{"id":"xl07IjbM8sh9","outputId":"896090fd-3e14-4abb-b7f8-9488d94e2d11","execution":{"iopub.status.busy":"2022-09-22T12:06:54.360463Z","iopub.execute_input":"2022-09-22T12:06:54.361188Z","iopub.status.idle":"2022-09-22T12:06:54.393460Z","shell.execute_reply.started":"2022-09-22T12:06:54.361147Z","shell.execute_reply":"2022-09-22T12:06:54.392358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_triplet(model, data_loader, num_epochs, lr=0.001):\n    model.train()\n    loss = torch.nn.TripletMarginLoss()\n    loss_history = []\n    print(f'lr: {lr}')\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    for epoch in range(1, num_epochs+1):\n        loss_accum = 0\n        loss_cnt = 0\n        for xa, xp, xn in tqdm(data_loader, desc=f'train {epoch}/{num_epochs}'):\n            ya = model(xa.to(device))\n            yp = model(xp.to(device))\n            yn = model(xn.to(device))\n            loss_data = loss(ya, yp, yn)\n            \n            optimizer.zero_grad()\n            loss_data.backward()\n            optimizer.step()\n            \n            loss_accum += float(loss_data)\n            loss_cnt += 1\n\n        loss_value = loss_accum / loss_cnt\n        loss_history.append(loss_value)\n        print(f'loss: {loss_value}')\n\n        if loss_value > loss_history[-1]:\n            lr *= 0.1\n            print(f'lr: {lr}')\n            optimizer = optim.Adam(model.parameters(), lr=lr)\n\n    return loss_history","metadata":{"id":"4az7iXvujIux","execution":{"iopub.status.busy":"2022-09-22T12:06:54.398168Z","iopub.execute_input":"2022-09-22T12:06:54.398462Z","iopub.status.idle":"2022-09-22T12:06:54.407238Z","shell.execute_reply.started":"2022-09-22T12:06:54.398436Z","shell.execute_reply":"2022-09-22T12:06:54.406155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import psutil\ndata_loader = torch.utils.data.DataLoader(dataset, batch_size=32, num_workers=psutil.cpu_count())\npsutil.cpu_count()","metadata":{"id":"4ZbEaT2d048T","outputId":"a6cfec9b-dd52-4c9e-b7da-d4b8f17df73a","execution":{"iopub.status.busy":"2022-09-22T12:06:54.408683Z","iopub.execute_input":"2022-09-22T12:06:54.410117Z","iopub.status.idle":"2022-09-22T12:06:54.420260Z","shell.execute_reply.started":"2022-09-22T12:06:54.410088Z","shell.execute_reply":"2022-09-22T12:06:54.419116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_faceid_model():\n    model = torchvision.models.resnet50(pretrained=True)\n    model.fc = nn.Linear(model.fc.in_features, 16)\n    return model\n\ndef grayscale_fix_model(model):\n    w = model.conv1.weight.data.sum(axis=1).reshape(64, 1, 7, 7)\n    model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    model.conv1.weight.data = w\n    return model\n\ndef set_trainable(model):\n    model.requires_grad_(False)\n    model.fc.requires_grad_(True)\n\ndef bind_model2device(model):\n    model.to(device)\n\nmodel = create_faceid_model()\nmodel = grayscale_fix_model(model)\nset_trainable(model)\nbind_model2device(model)\n#summary(model)\nmodel.conv1, model.fc","metadata":{"id":"PQ5MsTvD2Ifs","outputId":"d0fc9abf-e1e4-4051-a659-6cdaae79f8a4","execution":{"iopub.status.busy":"2022-09-22T12:06:54.421898Z","iopub.execute_input":"2022-09-22T12:06:54.422466Z","iopub.status.idle":"2022-09-22T12:06:56.781312Z","shell.execute_reply.started":"2022-09-22T12:06:54.422430Z","shell.execute_reply":"2022-09-22T12:06:56.780342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_history = train_triplet(model, data_loader, 10)\nplt.plot(loss_history)\nplt.title('loss');","metadata":{"id":"DYnLNynr1pNS","outputId":"8ae787a8-8b99-4cf1-d65c-b626bd476382","execution":{"iopub.status.busy":"2022-09-22T12:06:56.782716Z","iopub.execute_input":"2022-09-22T12:06:56.783359Z","iopub.status.idle":"2022-09-22T12:08:19.985105Z","shell.execute_reply.started":"2022-09-22T12:06:56.783321Z","shell.execute_reply":"2022-09-22T12:08:19.983899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(model.fc.weight.cpu().detach().reshape(-1), bins=100);","metadata":{"id":"PSoePnKbXp58","outputId":"5e742904-b13e-4834-83a1-770707c17f8f","execution":{"iopub.status.busy":"2022-09-22T12:08:19.987120Z","iopub.execute_input":"2022-09-22T12:08:19.987572Z","iopub.status.idle":"2022-09-22T12:08:20.646352Z","shell.execute_reply.started":"2022-09-22T12:08:19.987526Z","shell.execute_reply":"2022-09-22T12:08:20.645358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model(dataset[42][0].reshape(1, 1, 224, 224).to(device))","metadata":{"id":"DmNlocWSW2Fa","outputId":"438e2c13-ebd1-4219-afcf-5a9ef6529bd4","execution":{"iopub.status.busy":"2022-09-22T12:08:20.647664Z","iopub.execute_input":"2022-09-22T12:08:20.648684Z","iopub.status.idle":"2022-09-22T12:08:20.684286Z","shell.execute_reply.started":"2022-09-22T12:08:20.648644Z","shell.execute_reply":"2022-09-22T12:08:20.683431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cos_similarity(v1, v2):\n    val = np.inner(v1,v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n    return val.reshape(-1)[0]\n\ndef euc_similarity(v1, v2):\n    return np.linalg.norm(v1-v2)","metadata":{"id":"GaluetAiclVn","execution":{"iopub.status.busy":"2022-09-22T12:08:20.685638Z","iopub.execute_input":"2022-09-22T12:08:20.686209Z","iopub.status.idle":"2022-09-22T12:08:20.691972Z","shell.execute_reply.started":"2022-09-22T12:08:20.686170Z","shell.execute_reply":"2022-09-22T12:08:20.690883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(10):\n    v1 = model(dataset[42][0].reshape(1, 1, 224, 224).to(device)).cpu().detach().numpy()\n    v2 = model(dataset[42][1].reshape(1, 1, 224, 224).to(device)).cpu().detach().numpy()\n    v3 = model(dataset[42][2].reshape(1, 1, 224, 224).to(device)).cpu().detach().numpy()\n    print(euc_similarity(v1, v2), euc_similarity(v1, v3), cos_similarity(v1, v2), cos_similarity(v1, v3))","metadata":{"id":"fFtYrsKntNsX","outputId":"7244266d-d69a-483e-bc4b-4853b3009e7d","execution":{"iopub.status.busy":"2022-09-22T12:08:20.693610Z","iopub.execute_input":"2022-09-22T12:08:20.693954Z","iopub.status.idle":"2022-09-22T12:08:21.263836Z","shell.execute_reply.started":"2022-09-22T12:08:20.693921Z","shell.execute_reply":"2022-09-22T12:08:21.262804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.requires_grad_(True)\nloss_history = train_triplet(model, data_loader, 5, lr=0.00001)\nplt.plot(loss_history)\nplt.title('loss');","metadata":{"id":"FwJflhX1aeym","outputId":"de38b2ce-ec38-4e20-b8af-29de96a53be4","execution":{"iopub.status.busy":"2022-09-22T12:08:21.265362Z","iopub.execute_input":"2022-09-22T12:08:21.265998Z","iopub.status.idle":"2022-09-22T12:10:16.819336Z","shell.execute_reply.started":"2022-09-22T12:08:21.265958Z","shell.execute_reply":"2022-09-22T12:10:16.818324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(model.fc.weight.cpu().detach().reshape(-1), bins=100);","metadata":{"id":"awzalcn6bpTe","outputId":"3926ea4f-f4d2-4902-d2d6-da44f976a256","execution":{"iopub.status.busy":"2022-09-22T12:10:16.821062Z","iopub.execute_input":"2022-09-22T12:10:16.821352Z","iopub.status.idle":"2022-09-22T12:10:17.355433Z","shell.execute_reply.started":"2022-09-22T12:10:16.821321Z","shell.execute_reply":"2022-09-22T12:10:17.354611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(10):\n    v1 = model(dataset[42][0].reshape(1, 1, 224, 224).to(device)).cpu().detach().numpy()\n    v2 = model(dataset[42][1].reshape(1, 1, 224, 224).to(device)).cpu().detach().numpy()\n    v3 = model(dataset[42][2].reshape(1, 1, 224, 224).to(device)).cpu().detach().numpy()\n    print(euc_similarity(v1, v2), euc_similarity(v1, v3), cos_similarity(v1, v2), cos_similarity(v1, v3))","metadata":{"id":"e90luCJ3kZ9Q","outputId":"1356b994-f4fb-47ec-da11-5fb86ae56262","execution":{"iopub.status.busy":"2022-09-22T12:10:17.356863Z","iopub.execute_input":"2022-09-22T12:10:17.357339Z","iopub.status.idle":"2022-09-22T12:10:17.972788Z","shell.execute_reply.started":"2022-09-22T12:10:17.357300Z","shell.execute_reply":"2022-09-22T12:10:17.971712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, f'faceid-model-{loss_history[-1]}.pt')\n!ls -l faceid-model-*.pt","metadata":{"id":"37ox4WYL7-Tb","outputId":"519ac00f-3b1a-4761-f2c7-802805940540","execution":{"iopub.status.busy":"2022-09-22T12:10:17.974294Z","iopub.execute_input":"2022-09-22T12:10:17.975661Z","iopub.status.idle":"2022-09-22T12:10:19.141651Z","shell.execute_reply.started":"2022-09-22T12:10:17.975620Z","shell.execute_reply":"2022-09-22T12:10:19.140472Z"},"trusted":true},"execution_count":null,"outputs":[]}]}