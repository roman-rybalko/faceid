{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4554559b",
   "metadata": {
    "papermill": {
     "duration": 0.007017,
     "end_time": "2022-09-21T06:16:30.708243",
     "exception": false,
     "start_time": "2022-09-21T06:16:30.701226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# How can I use a pre-trained neural network with grayscale images?\n",
    "This work is aimed to validate this answer at StackOverflow: https://stackoverflow.com/questions/51995977/how-can-i-use-a-pre-trained-neural-network-with-grayscale-images#answer-54777347\n",
    "\n",
    "The idea is to fix the first convolution layer by summing up the weights over the color channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a86c29e5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-09-21T06:16:30.721254Z",
     "iopub.status.busy": "2022-09-21T06:16:30.720239Z",
     "iopub.status.idle": "2022-09-21T06:16:43.935136Z",
     "shell.execute_reply": "2022-09-21T06:16:43.933690Z"
    },
    "papermill": {
     "duration": 13.224867,
     "end_time": "2022-09-21T06:16:43.938270",
     "exception": false,
     "start_time": "2022-09-21T06:16:30.713403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/imagenetmini-1000/imagenet-mini/val/n01531178/ILSVRC2012_val_00029581.JPEG\n",
      "/kaggle/input/imagenetmini-1000/imagenet-mini/val/n01531178/ILSVRC2012_val_00048710.JPEG\n",
      "/kaggle/input/imagenetmini-1000/imagenet-mini/val/n01531178/ILSVRC2012_val_00001274.JPEG\n",
      "/kaggle/input/imagenetmini-1000/imagenet-mini/val/n01531178/ILSVRC2012_val_00025151.JPEG\n",
      "/kaggle/input/imagenetmini-1000/imagenet-mini/val/n02412080/ILSVRC2012_val_00017145.JPEG\n",
      "/kaggle/input/imagenetmini-1000/imagenet-mini/val/n02412080/ILSVRC2012_val_00019446.JPEG\n",
      "/kaggle/input/imagenetmini-1000/imagenet-mini/val/n02098413/ILSVRC2012_val_00049190.JPEG\n",
      "/kaggle/input/imagenetmini-1000/imagenet-mini/val/n02098413/ILSVRC2012_val_00007497.JPEG\n",
      "/kaggle/input/imagenetmini-1000/imagenet-mini/val/n02098413/ILSVRC2012_val_00033278.JPEG\n",
      "38676\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm # progress bar\n",
    "import matplotlib.pyplot as plt # drawing\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "fcnt = 0\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        fcnt += 1\n",
    "        if fcnt < 10:\n",
    "            print(os.path.join(dirname, filename))\n",
    "print(fcnt)\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a94ca2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T06:16:43.951441Z",
     "iopub.status.busy": "2022-09-21T06:16:43.950969Z",
     "iopub.status.idle": "2022-09-21T06:16:43.955690Z",
     "shell.execute_reply": "2022-09-21T06:16:43.954716Z"
    },
    "papermill": {
     "duration": 0.014213,
     "end_time": "2022-09-21T06:16:43.958093",
     "exception": false,
     "start_time": "2022-09-21T06:16:43.943880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = '/kaggle/input/imagenetmini-1000/imagenet-mini/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4383dfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T06:16:43.972008Z",
     "iopub.status.busy": "2022-09-21T06:16:43.971209Z",
     "iopub.status.idle": "2022-09-21T06:16:46.152066Z",
     "shell.execute_reply": "2022-09-21T06:16:46.150887Z"
    },
    "papermill": {
     "duration": 2.190562,
     "end_time": "2022-09-21T06:16:46.154663",
     "exception": false,
     "start_time": "2022-09-21T06:16:43.964101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'), 'CPU')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device, torch.cuda.get_device_properties(device) if torch.cuda.is_available() else 'CPU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df25cfd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T06:16:46.167610Z",
     "iopub.status.busy": "2022-09-21T06:16:46.167029Z",
     "iopub.status.idle": "2022-09-21T06:16:46.698788Z",
     "shell.execute_reply": "2022-09-21T06:16:46.697927Z"
    },
    "papermill": {
     "duration": 0.540613,
     "end_time": "2022-09-21T06:16:46.700859",
     "exception": false,
     "start_time": "2022-09-21T06:16:46.160246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data: 100%|██████████| 1000/1000 [00:00<00:00, 1980.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(34745, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PIL\n",
    "\n",
    "class ImageNetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        for cl in tqdm(os.listdir(data_dir), desc='data'):\n",
    "            for f in os.listdir(f'{data_dir}/{cl}'):\n",
    "                self.data += [(f'{data_dir}/{cl}/{f}', cl)]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        assert index >= 0\n",
    "        assert index < len(self.data)\n",
    "        f, cl = self.data[index]\n",
    "        img = PIL.Image.open(f).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, cl, f\n",
    "    \n",
    "    def classes(self):\n",
    "        return list(set(cl for f, cl in self.data))\n",
    "    \n",
    "    def get_class(self, index):\n",
    "        assert index >= 0\n",
    "        assert index < len(self.data)\n",
    "        f, cl = self.data[index]\n",
    "        return cl\n",
    "\n",
    "dataset = ImageNetDataset(data_dir)\n",
    "len(dataset), len(dataset.classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fed87bd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T06:16:46.715040Z",
     "iopub.status.busy": "2022-09-21T06:16:46.714626Z",
     "iopub.status.idle": "2022-09-21T06:16:46.726671Z",
     "shell.execute_reply": "2022-09-21T06:16:46.724822Z"
    },
    "papermill": {
     "duration": 0.022409,
     "end_time": "2022-09-21T06:16:46.729450",
     "exception": false,
     "start_time": "2022-09-21T06:16:46.707041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, loader, out_cnt=1000):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    weights = []\n",
    "    for x, _, _ in tqdm(loader, desc='eval'):\n",
    "        ws = model(x.to(device))\n",
    "        weights += [ws.cpu().detach().reshape(-1, out_cnt)]\n",
    "        predictions += [torch.argmax(ws, dim=1).cpu().detach().reshape(-1, 1)]\n",
    "    return np.vstack(predictions), np.vstack(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d7e336b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T06:16:46.748955Z",
     "iopub.status.busy": "2022-09-21T06:16:46.747833Z",
     "iopub.status.idle": "2022-09-21T06:16:47.792872Z",
     "shell.execute_reply": "2022-09-21T06:16:47.791478Z"
    },
    "papermill": {
     "duration": 1.058101,
     "end_time": "2022-09-21T06:16:47.795660",
     "exception": false,
     "start_time": "2022-09-21T06:16:46.737559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def metrics(classes, dataset):\n",
    "    assert len(classes) == len(dataset)\n",
    "    classes = classes.reshape(-1)\n",
    "    gt_classes = np.copy(classes)\n",
    "    cl_id = defaultdict(list)\n",
    "    for i in range(len(dataset)):\n",
    "        # find sample_ids for each class\n",
    "        cl = dataset.get_class(i)\n",
    "        cl_id[cl] += [i]\n",
    "    for cl in cl_id:\n",
    "        # guess the class - pick the most common class_id\n",
    "        cmn_cl = Counter(classes[cl_id[cl]]).most_common(1)[0][0]\n",
    "        gt_classes[cl_id[cl]] = cmn_cl\n",
    "    return sklearn.metrics.precision_score(gt_classes, classes, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f95055f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T06:16:47.810124Z",
     "iopub.status.busy": "2022-09-21T06:16:47.809716Z",
     "iopub.status.idle": "2022-09-21T06:16:47.818819Z",
     "shell.execute_reply": "2022-09-21T06:16:47.817646Z"
    },
    "papermill": {
     "duration": 0.019016,
     "end_time": "2022-09-21T06:16:47.821141",
     "exception": false,
     "start_time": "2022-09-21T06:16:47.802125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def validate(model, dataset):\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=16, num_workers=psutil.cpu_count())\n",
    "    cl, w = predict(model, data_loader)\n",
    "    return metrics(cl, dataset)\n",
    "\n",
    "psutil.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd5166da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T06:16:47.835803Z",
     "iopub.status.busy": "2022-09-21T06:16:47.835369Z",
     "iopub.status.idle": "2022-09-21T06:17:09.611444Z",
     "shell.execute_reply": "2022-09-21T06:17:09.610190Z"
    },
    "papermill": {
     "duration": 21.786709,
     "end_time": "2022-09-21T06:17:09.614256",
     "exception": false,
     "start_time": "2022-09-21T06:16:47.827547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: created directory '/root/.cache/torch'\r\n",
      "mkdir: created directory '/root/.cache/torch/hub'\r\n",
      "mkdir: created directory '/root/.cache/torch/hub/checkpoints/'\r\n",
      "'/kaggle/input/torchvision-resnet-pretrained/resnet101-63fe2227.pth' -> '/root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth'\r\n",
      "'/kaggle/input/torchvision-resnet-pretrained/resnet101-cd907fc2.pth' -> '/root/.cache/torch/hub/checkpoints/resnet101-cd907fc2.pth'\r\n",
      "'/kaggle/input/torchvision-resnet-pretrained/resnet152-394f9c45.pth' -> '/root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth'\r\n",
      "'/kaggle/input/torchvision-resnet-pretrained/resnet152-f82ba261.pth' -> '/root/.cache/torch/hub/checkpoints/resnet152-f82ba261.pth'\r\n",
      "'/kaggle/input/torchvision-resnet-pretrained/resnet18-f37072fd.pth' -> '/root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth'\r\n",
      "'/kaggle/input/torchvision-resnet-pretrained/resnet34-b627a593.pth' -> '/root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth'\r\n",
      "'/kaggle/input/torchvision-resnet-pretrained/resnet50-0676ba61.pth' -> '/root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth'\r\n",
      "'/kaggle/input/torchvision-resnet-pretrained/resnet50-11ad3fa6.pth' -> '/root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth'\r\n",
      "renamed '/root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth' -> '/root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth'\r\n",
      "renamed '/root/.cache/torch/hub/checkpoints/resnet101-cd907fc2.pth' -> '/root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth'\r\n",
      "renamed '/root/.cache/torch/hub/checkpoints/resnet152-f82ba261.pth' -> '/root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth'\r\n"
     ]
    }
   ],
   "source": [
    "# Updating to the recent pretrained data\n",
    "!mkdir -pv ~/.cache/torch/hub/checkpoints/\n",
    "!cp -av /kaggle/input/torchvision-resnet-pretrained/resnet*.pth ~/.cache/torch/hub/checkpoints/\n",
    "!mv -vf ~/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth ~/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
    "!mv -vf ~/.cache/torch/hub/checkpoints/resnet101-cd907fc2.pth ~/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
    "!mv -vf ~/.cache/torch/hub/checkpoints/resnet152-f82ba261.pth ~/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aae0286e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T06:17:09.631484Z",
     "iopub.status.busy": "2022-09-21T06:17:09.630694Z",
     "iopub.status.idle": "2022-09-21T06:17:09.637956Z",
     "shell.execute_reply": "2022-09-21T06:17:09.636796Z"
    },
    "papermill": {
     "duration": 0.018827,
     "end_time": "2022-09-21T06:17:09.640468",
     "exception": false,
     "start_time": "2022-09-21T06:17:09.621641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rn_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def resnet_transform(img):\n",
    "    img = rn_transform(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34dba025",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T06:17:09.658179Z",
     "iopub.status.busy": "2022-09-21T06:17:09.657395Z",
     "iopub.status.idle": "2022-09-21T06:43:29.254721Z",
     "shell.execute_reply": "2022-09-21T06:43:29.252788Z"
    },
    "papermill": {
     "duration": 1579.61012,
     "end_time": "2022-09-21T06:43:29.257703",
     "exception": false,
     "start_time": "2022-09-21T06:17:09.647583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data: 100%|██████████| 1000/1000 [00:00<00:00, 1724.49it/s]\n",
      "eval: 100%|██████████| 2172/2172 [26:18<00:00,  1.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7440207224061016"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(\n",
    "    torchvision.models.resnet18(pretrained=True),\n",
    "    ImageNetDataset(data_dir, resnet_transform)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1c631bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T06:43:29.533455Z",
     "iopub.status.busy": "2022-09-21T06:43:29.532977Z",
     "iopub.status.idle": "2022-09-21T07:28:25.660515Z",
     "shell.execute_reply": "2022-09-21T07:28:25.658628Z"
    },
    "papermill": {
     "duration": 2696.271204,
     "end_time": "2022-09-21T07:28:25.664138",
     "exception": false,
     "start_time": "2022-09-21T06:43:29.392934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data: 100%|██████████| 1000/1000 [00:01<00:00, 758.56it/s]\n",
      "eval: 100%|██████████| 2172/2172 [44:53<00:00,  1.24s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8000863433587566"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(\n",
    "    torchvision.models.resnet34(pretrained=True),\n",
    "    ImageNetDataset(data_dir, resnet_transform)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68aa5be7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T07:28:26.314742Z",
     "iopub.status.busy": "2022-09-21T07:28:26.313930Z",
     "iopub.status.idle": "2022-09-21T08:29:43.716085Z",
     "shell.execute_reply": "2022-09-21T08:29:43.714407Z"
    },
    "papermill": {
     "duration": 3677.771707,
     "end_time": "2022-09-21T08:29:43.721574",
     "exception": false,
     "start_time": "2022-09-21T07:28:25.949867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data: 100%|██████████| 1000/1000 [00:00<00:00, 1595.41it/s]\n",
      "eval: 100%|██████████| 2172/2172 [1:01:14<00:00,  1.69s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9063174557490287"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(\n",
    "    torchvision.models.resnet50(pretrained=True),\n",
    "    ImageNetDataset(data_dir, resnet_transform)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03168889",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T08:29:44.623346Z",
     "iopub.status.busy": "2022-09-21T08:29:44.622084Z",
     "iopub.status.idle": "2022-09-21T10:08:05.360507Z",
     "shell.execute_reply": "2022-09-21T10:08:05.358256Z"
    },
    "papermill": {
     "duration": 5901.234015,
     "end_time": "2022-09-21T10:08:05.363577",
     "exception": false,
     "start_time": "2022-09-21T08:29:44.129562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data: 100%|██████████| 1000/1000 [00:05<00:00, 183.54it/s]\n",
      "eval: 100%|██████████| 2172/2172 [1:38:12<00:00,  2.71s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9227802561519644"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(\n",
    "    torchvision.models.resnet101(pretrained=True),\n",
    "    ImageNetDataset(data_dir, resnet_transform)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9be71ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T10:08:06.562861Z",
     "iopub.status.busy": "2022-09-21T10:08:06.562145Z",
     "iopub.status.idle": "2022-09-21T12:28:33.355842Z",
     "shell.execute_reply": "2022-09-21T12:28:33.350841Z"
    },
    "papermill": {
     "duration": 8427.443467,
     "end_time": "2022-09-21T12:28:33.361336",
     "exception": false,
     "start_time": "2022-09-21T10:08:05.917869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data: 100%|██████████| 1000/1000 [00:00<00:00, 1183.82it/s]\n",
      "eval: 100%|██████████| 2172/2172 [2:20:20<00:00,  3.88s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9347244207799683"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(\n",
    "    torchvision.models.resnet152(pretrained=True),\n",
    "    ImageNetDataset(data_dir, resnet_transform)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24b73840",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T12:28:34.863854Z",
     "iopub.status.busy": "2022-09-21T12:28:34.863201Z",
     "iopub.status.idle": "2022-09-21T12:28:34.880310Z",
     "shell.execute_reply": "2022-09-21T12:28:34.878876Z"
    },
    "papermill": {
     "duration": 0.829519,
     "end_time": "2022-09-21T12:28:34.883275",
     "exception": false,
     "start_time": "2022-09-21T12:28:34.053756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gr_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.functional.to_grayscale,\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def grayscale_transform(img):\n",
    "    img = gr_transform(img)\n",
    "    return img\n",
    "\n",
    "def grayscale_fix_model(model):\n",
    "    w = model.conv1.weight.data.sum(axis=1).reshape(64, 1, 7, 7)\n",
    "    model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    model.conv1.weight.data = w\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ced25821",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T12:28:36.253470Z",
     "iopub.status.busy": "2022-09-21T12:28:36.252811Z",
     "iopub.status.idle": "2022-09-21T12:54:04.287534Z",
     "shell.execute_reply": "2022-09-21T12:54:04.285824Z"
    },
    "papermill": {
     "duration": 1528.725228,
     "end_time": "2022-09-21T12:54:04.290450",
     "exception": false,
     "start_time": "2022-09-21T12:28:35.565222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data: 100%|██████████| 1000/1000 [00:07<00:00, 139.52it/s]\n",
      "eval: 100%|██████████| 2172/2172 [25:19<00:00,  1.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.33898402647863"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(\n",
    "    grayscale_fix_model(torchvision.models.resnet18(pretrained=True)),\n",
    "    ImageNetDataset(data_dir, grayscale_transform)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "739ceddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T12:54:06.049236Z",
     "iopub.status.busy": "2022-09-21T12:54:06.048757Z",
     "iopub.status.idle": "2022-09-21T13:53:28.299741Z",
     "shell.execute_reply": "2022-09-21T13:53:28.296266Z"
    },
    "papermill": {
     "duration": 3563.07085,
     "end_time": "2022-09-21T13:53:28.303064",
     "exception": false,
     "start_time": "2022-09-21T12:54:05.232214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data: 100%|██████████| 1000/1000 [00:05<00:00, 184.31it/s]\n",
      "eval: 100%|██████████| 2172/2172 [59:14<00:00,  1.64s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7534033673909916"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(\n",
    "    grayscale_fix_model(torchvision.models.resnet50(pretrained=True)),\n",
    "    ImageNetDataset(data_dir, grayscale_transform)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df9d5861",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T13:53:30.679152Z",
     "iopub.status.busy": "2022-09-21T13:53:30.677784Z",
     "iopub.status.idle": "2022-09-21T13:53:30.706284Z",
     "shell.execute_reply": "2022-09-21T13:53:30.703514Z"
    },
    "papermill": {
     "duration": 1.457651,
     "end_time": "2022-09-21T13:53:30.712494",
     "exception": false,
     "start_time": "2022-09-21T13:53:29.254843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gr_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    torchvision.transforms.ToPILImage(),\n",
    "    torchvision.transforms.functional.to_grayscale,\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1aa969d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T13:53:34.665836Z",
     "iopub.status.busy": "2022-09-21T13:53:34.664931Z",
     "iopub.status.idle": "2022-09-21T14:19:52.111798Z",
     "shell.execute_reply": "2022-09-21T14:19:52.110330Z"
    },
    "papermill": {
     "duration": 1579.39558,
     "end_time": "2022-09-21T14:19:52.114499",
     "exception": false,
     "start_time": "2022-09-21T13:53:32.718919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data: 100%|██████████| 1000/1000 [00:00<00:00, 1077.92it/s]\n",
      "eval: 100%|██████████| 2172/2172 [26:15<00:00,  1.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.26182184486976545"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(\n",
    "    grayscale_fix_model(torchvision.models.resnet18(pretrained=True)),\n",
    "    ImageNetDataset(data_dir, grayscale_transform)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eab3ae8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T14:19:54.411955Z",
     "iopub.status.busy": "2022-09-21T14:19:54.410793Z",
     "iopub.status.idle": "2022-09-21T15:20:43.366811Z",
     "shell.execute_reply": "2022-09-21T15:20:43.365646Z"
    },
    "papermill": {
     "duration": 3650.177218,
     "end_time": "2022-09-21T15:20:43.369229",
     "exception": false,
     "start_time": "2022-09-21T14:19:53.192011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data: 100%|██████████| 1000/1000 [00:04<00:00, 218.51it/s]\n",
      "eval: 100%|██████████| 2172/2172 [1:00:42<00:00,  1.68s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19202762987480212"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(\n",
    "    grayscale_fix_model(torchvision.models.resnet50(pretrained=True)),\n",
    "    ImageNetDataset(data_dir, grayscale_transform)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95015b05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T15:20:46.098250Z",
     "iopub.status.busy": "2022-09-21T15:20:46.097810Z",
     "iopub.status.idle": "2022-09-21T15:20:46.104000Z",
     "shell.execute_reply": "2022-09-21T15:20:46.103099Z"
    },
    "papermill": {
     "duration": 1.424894,
     "end_time": "2022-09-21T15:20:46.105972",
     "exception": false,
     "start_time": "2022-09-21T15:20:44.681078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gr_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.functional.autocontrast,\n",
    "    torchvision.transforms.functional.to_grayscale,\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d448863",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T15:20:48.530559Z",
     "iopub.status.busy": "2022-09-21T15:20:48.529511Z",
     "iopub.status.idle": "2022-09-21T15:46:22.499660Z",
     "shell.execute_reply": "2022-09-21T15:46:22.497042Z"
    },
    "papermill": {
     "duration": 1535.185909,
     "end_time": "2022-09-21T15:46:22.502822",
     "exception": false,
     "start_time": "2022-09-21T15:20:47.316913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data: 100%|██████████| 1000/1000 [00:06<00:00, 164.24it/s]\n",
      "eval: 100%|██████████| 2172/2172 [25:26<00:00,  1.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3505540365520219"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(\n",
    "    grayscale_fix_model(torchvision.models.resnet18(pretrained=True)),\n",
    "    ImageNetDataset(data_dir, grayscale_transform)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cef3ecd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T15:46:25.398324Z",
     "iopub.status.busy": "2022-09-21T15:46:25.397326Z",
     "iopub.status.idle": "2022-09-21T16:46:42.668064Z",
     "shell.execute_reply": "2022-09-21T16:46:42.665341Z"
    },
    "papermill": {
     "duration": 3620.235907,
     "end_time": "2022-09-21T16:46:44.093753",
     "exception": false,
     "start_time": "2022-09-21T15:46:23.857846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data: 100%|██████████| 1000/1000 [00:00<00:00, 1046.07it/s]\n",
      "eval: 100%|██████████| 2172/2172 [1:00:13<00:00,  1.66s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7551014534465391"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(\n",
    "    grayscale_fix_model(torchvision.models.resnet50(pretrained=True)),\n",
    "    ImageNetDataset(data_dir, grayscale_transform)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37830.811966,
   "end_time": "2022-09-21T16:46:52.074214",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-21T06:16:21.262248",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
